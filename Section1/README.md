# Section1 : Introduction to Data Science
## EDA
### 정의
EDA(Exploratory Data Analysis)는 데이터 분석의 초기 단계로, 데이터를 다각도로 관찰하고 이해하기 위한 과정입니다. 이 과정은 데이터의 정제 및 전처리를 포함하며, 추가적으로 통계치와 시각화를 통해 데이터를 분석합니다.

### 중요성
원본 데이터(Raw Data)만으로는 인사이트를 얻기 어렵습니다. Raw 데이터에는 종종 불필요하거나 잘못된 데이터가 포함되어 있어, 이를 정제하고 전처리하는 과정이 필수적입니다. 이러한 작업을 통해 데이터 분석 과정에서 오류를 최소화할 수 있습니다.

### EDA 과정
1. **라이브러리 모듈 호출**
   - 데이터 분석에 필요한 라이브러리 모듈을 불러옵니다.
   ```python
   import numpy as np
   import pandas as pd
   ```

2. **데이터 업로드**
   - 분석할 데이터를 업로드합니다. 대부분의 데이터는 `.csv` 또는 `.excel` 형태의 파일입니다.
   ```python
   df = pd.read_csv('파일.csv')
   df = pd.read_excel('파일.xlsx')
   ```

3. **데이터 확인**
   - 데이터의 상태를 확인하고, pandas의 메서드를 사용해 문제가 있는지 탐색합니다.
   ```python
   df.head()
   df.shape
   df.info()
   df.describe()
   df.isnull().sum()
   df.duplicated().sum()
   ```

4. **데이터 정리**
   - 문제가 되는 데이터를 정리합니다.
     - 결측치 처리: 데이터 삭제 또는 채우기
     - 중복값 처리: 중복값 제거
     - 데이터 타입 변경: 적절한 데이터 타입으로 변경
     - 인덱스 재정렬: `df.reset_index(drop=True)`

### 추가 정보
- 데이터의 시각화: 데이터의 이해를 돕기 위해 matplotlib, seaborn 등의 라이브러리를 사용하여 데이터를 시각화합니다.
- 데이터의 상관관계 분석: 변수 간의 관계를 파악하기 위해 상관계수를 계산하고, 이를 시각화합니다.
- 피처 엔지니어링: 모델의 성능을 높이기 위해 적절한 피처를 선택하거나 생성합니다.

## Data Wrangling
데이터 랭글링은 데이터 분석의 핵심 과정 중 하나로, 원시 데이터를 분석에 적합한 형태로 변환하는 과정을 말합니다. 이 과정은 데이터 분석의 성공 여부를 결정짓는 중요한 단계입니다.

### 데이터 랭글링 과정

#### 1. 데이터 수집
데이터 수집은 분석의 출발점입니다. 데이터는 다양한 형태와 출처에서 수집될 수 있습니다.

- **직접 업로드**: 사용자가 직접 파일을 업로드하는 방식입니다. 예를 들어, Google Colab에서는 `files.upload()` 함수를 사용하여 로컬 시스템에서 파일을 업로드할 수 있습니다.
- **드라이브 마운트**: Google 드라이브와 같은 클라우드 서비스를 마운트하여 데이터를 불러올 수 있습니다.
- **URL을 통한 데이터 불러오기**: 웹에서 직접 데이터를 다운로드하는 방법입니다.

#### 2. 데이터 탐색
데이터 탐색은 데이터의 특성과 구조를 이해하는 과정입니다. 이 단계에서는 데이터의 품질과 구조적 문제를 파악합니다.

- **중복값**: 데이터셋에서 동일한 관측치가 두 번 이상 나타나는 경우입니다.
- **결측치**: 일부 데이터가 누락된 경우입니다.
- **이상치**: 데이터에서 정상 범위를 벗어난 값입니다.

```python
# 데이터 유관 확인
df.head()
# 데이터 프레임 정보 확인
df.info()
# 데이터 배열 확인 (행과 열)
df.shape
```

- **결측치 확인**
  ```python
  df.isnull()
  df.isnull().sum()
  ```
  
- **중복값 확인**
  ```python
  df.duplicated()
  df.duplicated().sum()
  ```

- **이상치 확인**
  ```python
  df.describe()
  ```

#### 3. 데이터 정제
데이터 정제는 탐색 과정에서 발견된 문제를 해결하는 단계입니다.

- **결측치 처리**
  - 결측치를 제거하거나 다른 값으로 대체합니다.
  - `dropna()` 메서드를 사용하여 결측치가 있는 행이나 열을 제거할 수 있습니다.
  - `fillna()` 메서드로 결측치를 다른 값으로 대체할 수 있습니다.

- **중복값 제거**
  - `drop_duplicates()` 메서드를 사용하여 중복된 행을 제거합니다.

- **데이터 형식 관리**
  - 데이터의 형식을 적절하게 변환하거나 조정합니다.

```python
# 결측치 제거
df.dropna()

# 중복값 제거
df.drop_duplicates()

# 인덱스 정렬
df.reset_index(drop=True)
```

이러한 과정을 통해 데이터를 정제하고 분석에 적합한 형태로 만들어, 데이터 분석의 정확도와 효율성을 높일 수 있습니다.

## 데이터 구조적 문제 해결책

데이터를 표준화된 규칙에 따라 구조화하는 것은 중요합니다. 이는 데이터를 분석하기 좋은 형태로 만들어줍니다.

### 구조적 문제

- **변수와 열**: 각 변수는 하나의 열을 구성해야 합니다.
- **관측치와 행**: 각 관측치는 하나의 행을 구성해야 합니다.
- **관측 단위와 표**: 각 유형의 관측 단위는 표를 구성해야 합니다.

#### 데이터 형식 변환: Long Format과 Wide Format

- **Long Format (Tidy Data)과 Wide Format**: 데이터는 long format 또는 wide format으로 구성될 수 있습니다.
- `.melt()`와 `.pivot_table()` 메서드를 사용하여 이러한 형식 간 변환을 수행할 수 있습니다.

```python
# Wide Format에서 Long Format으로 변환
pd.melt(insuline_test_clean, id_vars=['변경하지 않는 컬럼'], var_name='새로운 인덱스 이름', value_name='컬럼 이름')

# Long Format에서 Wide Format으로 변환
insuline_test_clean.pivot_table(values='값', index='인덱스', columns='컬럼')
```

#### 데이터 프레임 합치기

- **`concat()`**: 두 개 이상의 데이터 프레임을 연결합니다.
- **`merge()`**: 두 데이터 프레임을 특정 기준에 따라 병합합니다.

```python
# 데이터 프레임 연결
pd.concat([df1, df2])

# 데이터 프레임 병합
pd.merge(left=df_left, right=df_right, how='inner', on='키')
```

##### 병합 방법
- `how='left'`: 왼쪽 데이터 프레임을 기준으로 병합합니다.
- `how='right'`: 오른쪽 데이터 프레임을 기준으로 병합합니다.
- `how='inner'`: 두 데이터 프레임의 교집합을 기준으로 병합합니다.
- `how='outer'`: 두 데이터 프레임의 합집합을 기준으로 병합합니다.

이러한 방법을 통해 데이터의 구조적 문제를 해결하고, 분석에 적합한 형태로 데이터를 준비할 수 있습니다.

## Bayesian Theorem

## Central Limit Theorem

## Hypothesis Test

## AB test

## Linear Algebra

## PCA

## Clustering

## Gradient Descent